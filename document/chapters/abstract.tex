Nearshore bathymetry importance

Knowledge of nearshore bathymetry is crucial for every aspect of the blue economy, especially for research on successful adaption to anthropogenic climate change. Currently, it is very expensive to obtain reliable nearshore bathymetry at the regional scale because the shallow water area is dangerous to survey by boat. Because of the expense required to survey it, nearshore bathymetry data is not available  in many regions of the world. This data shortage is especially acute in the global south and big ocean states, which are also at the highest risk from climate change effects. 

Lidar Satellite-derived bathymetry

Recent developments in lidar remote sensing have proven that spaceborne lidar is capable of capturing nearshore bathymetry in the depth of 0-20 meters of the nearshore zone if  atmospheric conditions are good and the water is sufficiently clear. This provides a source of reliable, high-resolution bathymetric depth profiles that vary from 0-3 kilometers apart, depending on the orbit of the spacecraft. To find spacecraft passes that contain bathymetric data, signal processing is required to extract it. This project proposes an automated way of extracting bathymetry data from the lidar point locations, based on the density of the photon points in the underwater zone.

Existing global data

There is a global bathymetric dataset, GEBCO, which provides approximate depth data at approximately a 500m resolution. This data is of limited accuracy in the nearshore zone, because the source data is especially sparse in nearshore areas. This thesis proposes a method of using GEBCO data as a starting point, and incorporating the spaceborne lidar data via a Kalman Filter update. This results in a product with an upscaled spatial resolution that provides bathymetry without requiring any in-situ data.

Data assimilation via Kalman Updating

To implement the Kalman upscaling, first global data from GEBCO is clipped to the area of interest, and then interpolated bilinearly to 50m resolution. Then, the ICESat-2 photon data for the area is processed to find a series of point measurements containing bathymetric data. To fill in the gaps between these point measurements, the bathymetric points are subsampled and interpolated to the same resolution as the GEBCO data using universal kriging interpolator. This interpolar results in a raster of the estimated depth, and a raster of the estimated uncertainty at that point. To update the interpolated GEBCO raster, the Kalman gain is calculated for each raster cell in an elementwise manner, and using the Kalman state equation a new bathymetry grid is produced. If other data is available, the process can be applied recursively with other depth and uncertainty grids. The process can allow combination of any number of bathymetry datasets if their measurement uncertainty is known. 

Validation

To validate the method, the RMSE error is calculated between the resulting bathymetry grid and previously validated, high accuracy survey data. The validation will be applied at several global test sites to verify that the method generalizable to other regions.

Outlook 

The results of this research could allow easier methods of characterizing nearshore bathymetry in remote areas, and could also be extended to include temporal variation â€“ as more bathymetric data becomes available, it could be used measure the dynamic changes coastal systems. Data with this temporal dimension would provide valuable validation data for coastal dynamics models. The method could also be feasibly be extended on a global basis, to produce a global dataset of bathymetry on coasts with clear water.
